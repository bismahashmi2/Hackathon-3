"use strict";(globalThis.webpackChunkmy_book=globalThis.webpackChunkmy_book||[]).push([[7441],{2873(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>a,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"textbook/modules/sensors-perception/labs/lab-04-03","title":"Sensor Fusion with Extended Kalman Filter","description":"Objectives","source":"@site/docs/textbook/modules/04-sensors-perception/labs/lab-04-03.md","sourceDirName":"textbook/modules/04-sensors-perception/labs","slug":"/textbook/modules/sensors-perception/labs/lab-04-03","permalink":"/Hackathon-3/docs/textbook/modules/sensors-perception/labs/lab-04-03","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/textbook/modules/04-sensors-perception/labs/lab-04-03.md","tags":[],"version":"current","frontMatter":{"id":"lab-04-03","module_id":"04","title":"Sensor Fusion with Extended Kalman Filter","difficulty":"intermediate","tier":"simulation","duration_minutes":120},"sidebar":"tutorialSidebar","previous":{"title":"Camera Image Processing for Robotics","permalink":"/Hackathon-3/docs/textbook/modules/sensors-perception/labs/lab-04-02"},"next":{"title":"Sensors and Perception","permalink":"/Hackathon-3/docs/textbook/modules/sensors-perception/sensors-perception"}}');var r=t(4848),i=t(8453);const a={id:"lab-04-03",module_id:"04",title:"Sensor Fusion with Extended Kalman Filter",difficulty:"intermediate",tier:"simulation",duration_minutes:120},o="Lab 04-03: Sensor Fusion with Extended Kalman Filter",l={},d=[{value:"Objectives",id:"objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Materials",id:"materials",level:2},{value:"Background",id:"background",level:2},{value:"The Sensor Fusion Problem",id:"the-sensor-fusion-problem",level:3},{value:"Extended Kalman Filter",id:"extended-kalman-filter",level:3},{value:"Instructions",id:"instructions",level:2},{value:"Step 1: State Representation",id:"step-1-state-representation",level:3},{value:"Step 2: Prediction Step",id:"step-2-prediction-step",level:3},{value:"Step 3: Update Step",id:"step-3-update-step",level:3},{value:"Step 4: Complete EKF Class",id:"step-4-complete-ekf-class",level:3},{value:"Step 5: Test with MuJoCo Simulation",id:"step-5-test-with-mujoco-simulation",level:3},{value:"Step 6: Evaluate and Visualize Results",id:"step-6-evaluate-and-visualize-results",level:3},{value:"Expected Outcomes",id:"expected-outcomes",level:2},{value:"Rubric",id:"rubric",level:2},{value:"Common Errors",id:"common-errors",level:2},{value:"Extensions",id:"extensions",level:2},{value:"Related Content",id:"related-content",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"lab-04-03-sensor-fusion-with-extended-kalman-filter",children:"Lab 04-03: Sensor Fusion with Extended Kalman Filter"})}),"\n",(0,r.jsx)(n.h2,{id:"objectives",children:"Objectives"}),"\n",(0,r.jsx)(n.p,{children:"By the end of this lab, you will be able to:"}),"\n",(0,r.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Understand the principles of sensor fusion and state estimation"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Implement an Extended Kalman Filter (EKF) for orientation estimation"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Fuse accelerometer and gyroscope data to track robot orientation"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Evaluate filter performance and tune parameters"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Completed Lab 04-01 (IMU data reading)"}),"\n",(0,r.jsx)(n.li,{children:"Understanding of linear algebra (matrices, vectors)"}),"\n",(0,r.jsx)(n.li,{children:"Basic probability concepts (Gaussian distributions)"}),"\n",(0,r.jsx)(n.li,{children:"Familiarity with differential equations (helpful)"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"materials",children:"Materials"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Name"}),(0,r.jsx)(n.th,{children:"Tier"}),(0,r.jsx)(n.th,{children:"Notes"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"software"}),(0,r.jsx)(n.td,{children:"MuJoCo 3.0+"}),(0,r.jsx)(n.td,{children:"required"}),(0,r.jsx)(n.td,{children:"Physics simulation"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"software"}),(0,r.jsx)(n.td,{children:"Python 3.10+"}),(0,r.jsx)(n.td,{children:"required"}),(0,r.jsx)(n.td,{children:"Programming environment"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"software"}),(0,r.jsx)(n.td,{children:"NumPy, SciPy"}),(0,r.jsx)(n.td,{children:"required"}),(0,r.jsx)(n.td,{children:"Linear algebra"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"software"}),(0,r.jsx)(n.td,{children:"Matplotlib"}),(0,r.jsx)(n.td,{children:"required"}),(0,r.jsx)(n.td,{children:"Visualization"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"simulation"}),(0,r.jsx)(n.td,{children:"humanoid-sensors.xml"}),(0,r.jsx)(n.td,{children:"required"}),(0,r.jsx)(n.td,{children:"Model with IMU sensors"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"background",children:"Background"}),"\n",(0,r.jsx)(n.h3,{id:"the-sensor-fusion-problem",children:"The Sensor Fusion Problem"}),"\n",(0,r.jsx)(n.p,{children:"Individual sensors have limitations:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Gyroscope"}),": Accurate short-term, but drifts over time"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Accelerometer"}),": Noisy but provides absolute reference (gravity)"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"By combining them, we get the best of both worlds: accurate orientation tracking without drift."}),"\n",(0,r.jsx)(n.h3,{id:"extended-kalman-filter",children:"Extended Kalman Filter"}),"\n",(0,r.jsx)(n.p,{children:"The EKF is a recursive estimator for nonlinear systems:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Predict"}),": Use system model to predict next state"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Update"}),": Correct prediction using sensor measurements"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"For orientation estimation, we track quaternions or Euler angles."}),"\n",(0,r.jsx)(n.h2,{id:"instructions",children:"Instructions"}),"\n",(0,r.jsx)(n.h3,{id:"step-1-state-representation",children:"Step 1: State Representation"}),"\n",(0,r.jsx)(n.p,{children:"Define the state space for orientation estimation:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import numpy as np\nfrom scipy.spatial.transform import Rotation\n\nclass OrientationState:\n    """\n    State representation for orientation estimation.\n\n    State vector: [roll, pitch, yaw, bias_gx, bias_gy, bias_gz]\n    - roll, pitch, yaw: Euler angles (radians)\n    - bias_g*: Gyroscope bias terms\n    """\n\n    def __init__(self):\n        # State vector (6 elements)\n        self.x = np.zeros(6)\n\n        # State covariance (6x6)\n        self.P = np.eye(6) * 0.1\n\n        # Process noise covariance\n        self.Q = np.diag([\n            0.001,   # roll process noise\n            0.001,   # pitch process noise\n            0.001,   # yaw process noise\n            0.0001,  # bias_gx drift\n            0.0001,  # bias_gy drift\n            0.0001   # bias_gz drift\n        ])\n\n        # Measurement noise covariance (accelerometer)\n        self.R = np.diag([0.1, 0.1])  # roll, pitch from accel\n\n    @property\n    def euler(self):\n        """Get Euler angles (roll, pitch, yaw)."""\n        return self.x[:3]\n\n    @property\n    def gyro_bias(self):\n        """Get gyroscope bias estimate."""\n        return self.x[3:6]\n\n    def rotation_matrix(self):\n        """Get rotation matrix from current orientation."""\n        return Rotation.from_euler(\'xyz\', self.euler).as_matrix()\n\n# Initialize state\nstate = OrientationState()\nprint(f"Initial state: {state.x}")\nprint(f"Initial covariance diagonal: {np.diag(state.P)}")\n'})}),"\n",(0,r.jsx)("checkpoint",{children:(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Expected"}),": State initialized with zeros for angles and biases, identity-scaled covariance matrix."]})}),"\n",(0,r.jsx)(n.h3,{id:"step-2-prediction-step",children:"Step 2: Prediction Step"}),"\n",(0,r.jsx)(n.p,{children:"Implement the EKF prediction using gyroscope data:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def predict(state, gyro_measurement, dt):\n    """\n    EKF prediction step using gyroscope.\n\n    Args:\n        state: OrientationState object\n        gyro_measurement: [wx, wy, wz] angular velocity (rad/s)\n        dt: Time step (seconds)\n\n    Returns:\n        Updated state (in-place modification)\n    """\n    # Extract current state\n    roll, pitch, yaw = state.x[:3]\n    bias = state.x[3:6]\n\n    # Correct gyro measurement for bias\n    gyro_corrected = gyro_measurement - bias\n    wx, wy, wz = gyro_corrected\n\n    # State transition (Euler angle rates from body angular velocity)\n    # This is the nonlinear part that makes this an EKF\n    cos_roll = np.cos(roll)\n    sin_roll = np.sin(roll)\n    cos_pitch = np.cos(pitch)\n    tan_pitch = np.tan(pitch)\n\n    # Euler angle derivatives\n    roll_dot = wx + wy * sin_roll * tan_pitch + wz * cos_roll * tan_pitch\n    pitch_dot = wy * cos_roll - wz * sin_roll\n    yaw_dot = (wy * sin_roll + wz * cos_roll) / cos_pitch\n\n    # Predict state (Euler integration)\n    state.x[0] += roll_dot * dt\n    state.x[1] += pitch_dot * dt\n    state.x[2] += yaw_dot * dt\n    # Bias assumed constant (random walk)\n\n    # Jacobian of state transition (for covariance update)\n    F = compute_jacobian_F(state, gyro_corrected, dt)\n\n    # Predict covariance\n    state.P = F @ state.P @ F.T + state.Q * dt\n\n    return state\n\ndef compute_jacobian_F(state, gyro, dt):\n    """Compute state transition Jacobian."""\n    roll, pitch, yaw = state.x[:3]\n    wx, wy, wz = gyro\n\n    cos_roll = np.cos(roll)\n    sin_roll = np.sin(roll)\n    cos_pitch = np.cos(pitch)\n    sin_pitch = np.sin(pitch)\n    tan_pitch = np.tan(pitch)\n    sec_pitch = 1.0 / cos_pitch\n\n    # Jacobian matrix (partial derivatives)\n    F = np.eye(6)\n\n    # d(roll_dot)/d(roll)\n    F[0, 0] += dt * (wy * cos_roll * tan_pitch - wz * sin_roll * tan_pitch)\n    # d(roll_dot)/d(pitch)\n    F[0, 1] += dt * (wy * sin_roll + wz * cos_roll) * sec_pitch**2\n\n    # d(pitch_dot)/d(roll)\n    F[1, 0] += dt * (-wy * sin_roll - wz * cos_roll)\n\n    # d(yaw_dot)/d(roll)\n    F[2, 0] += dt * (wy * cos_roll - wz * sin_roll) * sec_pitch\n    # d(yaw_dot)/d(pitch)\n    F[2, 1] += dt * (wy * sin_roll + wz * cos_roll) * tan_pitch * sec_pitch\n\n    # Jacobian w.r.t. bias (negative effect on state)\n    F[0:3, 3:6] = -np.eye(3) * dt\n\n    return F\n\n# Test prediction\ntest_gyro = np.array([0.1, 0.0, 0.05])  # rad/s\ndt = 0.01\nstate = OrientationState()\nstate = predict(state, test_gyro, dt)\nprint(f"After prediction: roll={np.degrees(state.x[0]):.3f} deg")\n'})}),"\n",(0,r.jsx)("checkpoint",{children:(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Expected"}),": Small positive roll angle after prediction with positive roll rate."]})}),"\n",(0,r.jsx)(n.h3,{id:"step-3-update-step",children:"Step 3: Update Step"}),"\n",(0,r.jsx)(n.p,{children:"Implement the measurement update using accelerometer:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def update(state, accel_measurement, gravity=9.81):\n    """\n    EKF update step using accelerometer.\n\n    Accelerometer provides roll and pitch through gravity vector.\n    Note: Cannot estimate yaw from accelerometer alone.\n\n    Args:\n        state: OrientationState object\n        accel_measurement: [ax, ay, az] acceleration (m/s\xb2)\n        gravity: Expected gravity magnitude\n\n    Returns:\n        Updated state (in-place modification)\n    """\n    ax, ay, az = accel_measurement\n\n    # Normalize acceleration (assume stationary, measuring gravity)\n    accel_norm = np.sqrt(ax**2 + ay**2 + az**2)\n\n    # Skip update if acceleration is far from gravity (robot moving)\n```python\n```python\n    if abs(accel_norm - gravity) > 0.5:\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'        return state\n\n    ax_n, ay_n, az_n = ax/accel_norm, ay/accel_norm, az/accel_norm\n\n    # Measurement: roll and pitch from gravity\n    roll_meas = np.arctan2(ay_n, az_n)\n    pitch_meas = np.arctan2(-ax_n, np.sqrt(ay_n**2 + az_n**2))\n\n    z = np.array([roll_meas, pitch_meas])\n\n    # Measurement model: h(x) = [roll, pitch]\n    H = np.zeros((2, 6))\n    H[0, 0] = 1  # d(roll_meas)/d(roll)\n    H[1, 1] = 1  # d(pitch_meas)/d(pitch)\n\n    # Innovation (measurement residual)\n    z_pred = state.x[:2]\n    y = z - z_pred\n\n    # Wrap angles to [-pi, pi]\n    y = np.arctan2(np.sin(y), np.cos(y))\n\n    # Innovation covariance\n    S = H @ state.P @ H.T + state.R\n\n    # Kalman gain\n    K = state.P @ H.T @ np.linalg.inv(S)\n\n    # Update state\n    state.x = state.x + K @ y\n\n    # Update covariance (Joseph form for numerical stability)\n    I_KH = np.eye(6) - K @ H\n    state.P = I_KH @ state.P @ I_KH.T + K @ state.R @ K.T\n\n    return state\n\n# Test update\ntest_accel = np.array([0.0, 0.5, -9.8])  # Slight roll\nstate = OrientationState()\nstate = update(state, test_accel)\nprint(f"After update: roll={np.degrees(state.x[0]):.3f} deg")\nprint(f"Expected roll: {np.degrees(np.arctan2(0.5, 9.8)):.3f} deg")\n'})}),"\n",(0,r.jsx)("checkpoint",{children:(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Expected"}),": Roll angle close to arctan2(0.5, 9.8) \u2248 2.9 degrees."]})}),"\n",(0,r.jsx)(n.h3,{id:"step-4-complete-ekf-class",children:"Step 4: Complete EKF Class"}),"\n",(0,r.jsx)(n.p,{children:"Combine prediction and update into a reusable class:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'class OrientationEKF:\n    """\n    Extended Kalman Filter for IMU-based orientation estimation.\n    """\n\n    def __init__(self,\n                 process_noise_gyro=0.001,\n                 process_noise_bias=0.0001,\n                 measurement_noise=0.1):\n        """\n        Initialize EKF.\n\n        Args:\n            process_noise_gyro: Variance for gyro-based prediction\n            process_noise_bias: Variance for bias random walk\n            measurement_noise: Variance for accelerometer measurements\n        """\n        self.state = OrientationState()\n        self.state.Q = np.diag([\n            process_noise_gyro, process_noise_gyro, process_noise_gyro,\n            process_noise_bias, process_noise_bias, process_noise_bias\n        ])\n        self.state.R = np.diag([measurement_noise, measurement_noise])\n\n        self.initialized = False\n\n    def initialize(self, accel_measurement):\n        """Initialize orientation from accelerometer."""\n        ax, ay, az = accel_measurement\n        norm = np.sqrt(ax**2 + ay**2 + az**2)\n        ax, ay, az = ax/norm, ay/norm, az/norm\n\n        self.state.x[0] = np.arctan2(ay, az)  # roll\n        self.state.x[1] = np.arctan2(-ax, np.sqrt(ay**2 + az**2))  # pitch\n        self.state.x[2] = 0  # yaw (cannot determine from accel)\n\n        self.initialized = True\n\n    def process(self, gyro, accel, dt):\n        """\n        Process one IMU sample.\n\n        Args:\n            gyro: [wx, wy, wz] angular velocity (rad/s)\n            accel: [ax, ay, az] acceleration (m/s\xb2)\n            dt: Time step (seconds)\n\n        Returns:\n            Estimated Euler angles [roll, pitch, yaw]\n        """\n        if not self.initialized:\n            self.initialize(accel)\n\n        # Predict with gyro\n        predict(self.state, gyro, dt)\n\n        # Update with accelerometer\n        update(self.state, accel)\n\n        return self.state.euler.copy()\n\n    def get_rotation_matrix(self):\n        """Get current orientation as rotation matrix."""\n        return self.state.rotation_matrix()\n\n# Create EKF instance\nekf = OrientationEKF(\n    process_noise_gyro=0.001,\n    process_noise_bias=0.0001,\n    measurement_noise=0.1\n)\nprint("EKF initialized")\n'})}),"\n",(0,r.jsx)("checkpoint",{children:(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Expected"}),": EKF class created with configurable noise parameters."]})}),"\n",(0,r.jsx)(n.h3,{id:"step-5-test-with-mujoco-simulation",children:"Step 5: Test with MuJoCo Simulation"}),"\n",(0,r.jsx)(n.p,{children:"Run the EKF on simulated IMU data:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mujoco\nimport matplotlib.pyplot as plt\n\n# Load model\nmodel = mujoco.MjModel.from_xml_path("textbook/assets/robot-models/mujoco/humanoid-sensors.xml")\ndata = mujoco.MjData(model)\n\n# Get sensor IDs\naccel_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SENSOR, "torso_accelerometer")\ngyro_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SENSOR, "torso_gyroscope")\n\ndef get_imu_readings(model, data, accel_id, gyro_id):\n    """Extract IMU readings from sensor data."""\n    accel_adr = model.sensor_adr[accel_id]\n    gyro_adr = model.sensor_adr[gyro_id]\n\n    accel = data.sensordata[accel_adr:accel_adr+3].copy()\n    gyro = data.sensordata[gyro_adr:gyro_adr+3].copy()\n\n    return accel, gyro\n\ndef get_true_orientation(data, body_name="torso"):\n    """Get ground truth orientation from simulation."""\n    body_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_BODY, body_name)\n    quat = data.xquat[body_id]  # [w, x, y, z]\n\n    # Convert to Euler\n    rot = Rotation.from_quat([quat[1], quat[2], quat[3], quat[0]])  # scipy uses [x,y,z,w]\n    return rot.as_euler(\'xyz\')\n\n# Run simulation with EKF\nekf = OrientationEKF()\ndt = model.opt.timestep\nduration = 5.0\nn_steps = int(duration / dt)\n\n# Storage\ntimes = np.zeros(n_steps)\nestimated_euler = np.zeros((n_steps, 3))\ntrue_euler = np.zeros((n_steps, 3))\n\n# Apply perturbation\nmujoco.mj_resetData(model, data)\ndata.qvel[3] = 0.5  # Angular velocity perturbation\n\nfor i in range(n_steps):\n    mujoco.mj_step(model, data)\n\n    # Get sensor readings\n    accel, gyro = get_imu_readings(model, data, accel_id, gyro_id)\n\n    # Run EKF\n    euler = ekf.process(gyro, accel, dt)\n\n    # Store results\n    times[i] = data.time\n    estimated_euler[i] = euler\n    true_euler[i] = get_true_orientation(data)\n\nprint("Simulation complete")\nprint(f"Final estimated: {np.degrees(estimated_euler[-1])}")\nprint(f"Final true: {np.degrees(true_euler[-1])}")\n'})}),"\n",(0,r.jsx)("checkpoint",{children:(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Expected"}),": EKF runs without errors, estimated and true orientations should be similar."]})}),"\n",(0,r.jsx)(n.h3,{id:"step-6-evaluate-and-visualize-results",children:"Step 6: Evaluate and Visualize Results"}),"\n",(0,r.jsx)(n.p,{children:"Compare EKF estimates to ground truth:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def plot_ekf_results(times, estimated, true):\n    \"\"\"Plot EKF performance comparison.\"\"\"\n    fig, axes = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n    labels = ['Roll', 'Pitch', 'Yaw']\n\n    for i, (ax, label) in enumerate(zip(axes, labels)):\n        ax.plot(times, np.degrees(true[:, i]), 'b-', label='Ground Truth', linewidth=2)\n        ax.plot(times, np.degrees(estimated[:, i]), 'r--', label='EKF Estimate', linewidth=1.5)\n        ax.set_ylabel(f'{label} (degrees)')\n        ax.legend()\n        ax.grid(True)\n\n    axes[-1].set_xlabel('Time (s)')\n    axes[0].set_title('EKF Orientation Estimation Performance')\n\n    plt.tight_layout()\n    plt.savefig('ekf_results.png', dpi=150)\n    plt.show()\n\ndef compute_rmse(estimated, true):\n    \"\"\"Compute RMSE for each Euler angle.\"\"\"\n    errors = estimated - true\n    # Wrap angle errors\n    errors = np.arctan2(np.sin(errors), np.cos(errors))\n    rmse = np.sqrt(np.mean(errors**2, axis=0))\n    return np.degrees(rmse)\n\n# Plot results\nplot_ekf_results(times, estimated_euler, true_euler)\n\n# Compute error metrics\nrmse = compute_rmse(estimated_euler, true_euler)\nprint(f\"RMSE (degrees): Roll={rmse[0]:.3f}, Pitch={rmse[1]:.3f}, Yaw={rmse[2]:.3f}\")\n"})}),"\n",(0,r.jsx)("checkpoint",{children:(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Expected"}),": RMSE should be small (< 5 degrees) for roll and pitch. Yaw may drift without magnetometer."]})}),"\n",(0,r.jsx)(n.h2,{id:"expected-outcomes",children:"Expected Outcomes"}),"\n",(0,r.jsx)(n.p,{children:"After completing this lab, you should have:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Code artifacts"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"orientation_state.py"}),": State representation class"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"ekf.py"}),": Complete EKF implementation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"imu_fusion.py"}),": Integration with MuJoCo sensors"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Visual outputs"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"ekf_results.png"}),": Comparison of estimated vs true orientation"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Understanding"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"State estimation principles"}),"\n",(0,r.jsx)(n.li,{children:"Kalman filter predict/update cycle"}),"\n",(0,r.jsx)(n.li,{children:"Sensor fusion concepts"}),"\n",(0,r.jsx)(n.li,{children:"Filter tuning strategies"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"rubric",children:"Rubric"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Criterion"}),(0,r.jsx)(n.th,{children:"Points"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"State representation"}),(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"Correct state vector and covariance initialization"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Prediction step"}),(0,r.jsx)(n.td,{children:"25"}),(0,r.jsx)(n.td,{children:"Proper gyro integration with Jacobian computation"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Update step"}),(0,r.jsx)(n.td,{children:"25"}),(0,r.jsx)(n.td,{children:"Correct accelerometer-based measurement update"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Integration"}),(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"Working fusion with MuJoCo simulation"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Evaluation"}),(0,r.jsx)(n.td,{children:"10"}),(0,r.jsx)(n.td,{children:"RMSE computation and visualization"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Code quality"}),(0,r.jsx)(n.td,{children:"10"}),(0,r.jsx)(n.td,{children:"Clear structure, comments, modularity"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Total"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"100"})}),(0,r.jsx)(n.td,{})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"common-errors",children:"Common Errors"}),"\n",(0,r.jsxs)("troubleshooting",{children:[(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Error"}),": Filter diverges (values grow unbounded)\n",(0,r.jsx)(n.strong,{children:"Solution"}),": Check Jacobian computation. Ensure covariance stays positive definite."]}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Error"}),": Yaw drifts significantly\n",(0,r.jsx)(n.strong,{children:"Solution"}),": This is expected without a magnetometer. Consider adding simulated magnetometer measurements."]}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Error"}),": Poor tracking during fast motion\n",(0,r.jsx)(n.strong,{children:"Solution"}),": Increase process noise Q or decrease measurement noise R to trust gyro more."]})]}),"\n",(0,r.jsx)(n.h2,{id:"extensions",children:"Extensions"}),"\n",(0,r.jsx)(n.p,{children:"For advanced students:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Unscented Kalman Filter"}),": Implement UKF for better nonlinear handling"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Quaternion EKF"}),": Use quaternions instead of Euler angles to avoid gimbal lock"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Magnetometer Integration"}),": Add heading correction using magnetometer"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"AHRS Implementation"}),": Build complete Attitude and Heading Reference System"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"related-content",children:"Related Content"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Theory"}),": Module 04 theory.md, Section 4.4 (Sensor Fusion)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Previous Labs"}),": Lab 04-01 (IMU), Lab 04-02 (Camera)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Next Module"}),": Module 05 (Dynamics and Control) uses orientation estimates"]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453(e,n,t){t.d(n,{R:()=>a,x:()=>o});var s=t(6540);const r={},i=s.createContext(r);function a(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);